"""
å¼·åŒ–ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ  - è¨­è¨ˆæ›¸ã®ã€Œç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆè¨­è¨ˆã€ã«åŸºã¥ãå®Ÿè£…
"""

import json
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List
from enum import Enum
import structlog
from collections import defaultdict


class LogLevel(Enum):
    """ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«å®šç¾©"""
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"


class AlertLevel(Enum):
    """ã‚¢ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«éšå±¤åŒ–"""
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"
    EMERGENCY = "emergency"


class MetricsCollector:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
    
    def __init__(self):
        self.counters = defaultdict(int)
        self.gauges = {}
        self.histograms = defaultdict(list)
        self.start_time = datetime.now()
    
    def record_success(self, operation: str, duration: float):
        """æˆåŠŸãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²"""
        self.counters[f"{operation}_success"] += 1
        self.histograms[f"{operation}_duration"].append(duration)
    
    def record_error(self, operation: str, error_type: str):
        """ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²"""
        self.counters[f"{operation}_error_{error_type}"] += 1
    
    def record_event(self, event_name: str, count: int = 1):
        """ã‚¤ãƒ™ãƒ³ãƒˆè¨˜éŒ²"""
        self.counters[event_name] += count
    
    def set_gauge(self, name: str, value: float):
        """ã‚²ãƒ¼ã‚¸ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨­å®š"""
        self.gauges[name] = value
    
    def get_health_summary(self) -> dict:
        """ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ã‚µãƒãƒªãƒ¼"""
        uptime = (datetime.now() - self.start_time).total_seconds()
        
        # æˆåŠŸç‡è¨ˆç®—
        total_operations = 0
        total_successes = 0
        
        for key, count in self.counters.items():
            if key.endswith('_success'):
                total_successes += count
                operation = key.replace('_success', '')
                # å¯¾å¿œã™ã‚‹ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ãƒˆã‚‚å«ã‚ã‚‹
                for error_key in self.counters:
                    if error_key.startswith(f"{operation}_error"):
                        total_operations += self.counters[error_key]
        
        total_operations += total_successes
        success_rate = (total_successes / total_operations * 100) if total_operations > 0 else 100.0
        
        # å¹³å‡å¿œç­”æ™‚é–“è¨ˆç®—
        avg_response_times = {}
        for key, durations in self.histograms.items():
            if durations:
                avg_response_times[key] = sum(durations) / len(durations)
        
        return {
            'uptime_seconds': uptime,
            'success_rate_percent': success_rate,
            'total_operations': total_operations,
            'avg_response_times': avg_response_times,
            'error_rates_by_type': self._get_error_rates(),
            'last_health_check': datetime.now().isoformat(),
            'gauges': self.gauges.copy()
        }
    
    def _get_error_rates(self) -> Dict[str, float]:
        """ã‚¨ãƒ©ãƒ¼ç‡ã‚’ã‚¿ã‚¤ãƒ—åˆ¥ã«å–å¾—"""
        error_rates = {}
        total_ops_by_type = defaultdict(int)
        
        # å„æ“ä½œã®ç·æ•°ã‚’è¨ˆç®—
        for key, count in self.counters.items():
            if '_success' in key or '_error' in key:
                operation = key.split('_')[0]
                total_ops_by_type[operation] += count
        
        # ã‚¨ãƒ©ãƒ¼ç‡ã‚’è¨ˆç®—
        for key, count in self.counters.items():
            if '_error' in key:
                parts = key.split('_')
                operation = parts[0]
                error_type = '_'.join(parts[2:])  # operation_error_type
                
                if total_ops_by_type[operation] > 0:
                    error_rate = (count / total_ops_by_type[operation]) * 100
                    error_rates[f"{operation}_{error_type}"] = error_rate
        
        return error_rates


class EnhancedLogger:
    """å¼·åŒ–ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, 
                 name: str = "timetree_notifier",
                 log_level: LogLevel = LogLevel.INFO,
                 log_file: Optional[Path] = None,
                 metrics_enabled: bool = True):
        
        self.name = name
        self.log_level = log_level
        self.log_file = log_file
        self.metrics_enabled = metrics_enabled
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å™¨
        self.metrics = MetricsCollector() if metrics_enabled else None
        
        # æ§‹é€ åŒ–ãƒ­ã‚°è¨­å®š
        self._setup_structured_logging()
        
        # æ¨™æº–ãƒ­ã‚°è¨­å®š
        self._setup_standard_logging()
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
        self.alert_config = self._load_alert_config()
    
    def _setup_structured_logging(self):
        """æ§‹é€ åŒ–ãƒ­ã‚°ã®è¨­å®š"""
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨ãƒ¬ãƒ™ãƒ«ã‚’è¿½åŠ ã™ã‚‹ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼
        def add_timestamp(logger, method_name, event_dict):
            event_dict['timestamp'] = datetime.now().isoformat()
            event_dict['level'] = method_name.upper()
            event_dict['logger'] = logger.name
            return event_dict
        
        # JSONå½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        def json_formatter(logger, method_name, event_dict):
            return json.dumps(event_dict, ensure_ascii=False, default=str)
        
        # structlogè¨­å®š
        structlog.configure(
            processors=[
                add_timestamp,
                structlog.processors.add_log_level,
                json_formatter,
            ],
            wrapper_class=structlog.make_filtering_bound_logger(
                getattr(logging, self.log_level.value)
            ),
            logger_factory=structlog.WriteLoggerFactory(),
            cache_logger_on_first_use=True,
        )
        
        self.structured_logger = structlog.get_logger(self.name)
    
    def _setup_standard_logging(self):
        """æ¨™æº–ãƒ­ã‚°ã®è¨­å®š"""
        self.logger = logging.getLogger(self.name)
        self.logger.setLevel(getattr(logging, self.log_level.value))
        
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(formatter)
        self.logger.addHandler(console_handler)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆæŒ‡å®šã•ã‚ŒãŸå ´åˆï¼‰
        if self.log_file:
            self.log_file.parent.mkdir(parents=True, exist_ok=True)
            file_handler = logging.FileHandler(self.log_file, encoding='utf-8')
            file_handler.setFormatter(formatter)
            self.logger.addHandler(file_handler)
    
    def _load_alert_config(self) -> Dict[AlertLevel, dict]:
        """ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šã®èª­ã¿è¾¼ã¿"""
        return {
            AlertLevel.INFO: {
                "channels": ["log"],
                "conditions": [
                    "new_events_detected > 0",
                    "successful_sync_completed"
                ]
            },
            AlertLevel.WARNING: {
                "channels": ["log", "slack"],
                "conditions": [
                    "error_rate > 5%",
                    "response_time > 30s",
                    "fallback_method_used"
                ]
            },
            AlertLevel.CRITICAL: {
                "channels": ["log", "slack", "email", "sms"],
                "conditions": [
                    "error_rate > 50%",
                    "all_notification_channels_failed",
                    "data_corruption_detected"
                ]
            },
            AlertLevel.EMERGENCY: {
                "channels": ["log", "slack", "email", "sms", "phone_call"],
                "conditions": [
                    "system_completely_down > 1h",
                    "security_breach_detected"
                ]
            }
        }
    
    def info(self, message: str, **kwargs):
        """æƒ…å ±ãƒ­ã‚°"""
        self._log(LogLevel.INFO, message, **kwargs)
    
    def warning(self, message: str, **kwargs):
        """è­¦å‘Šãƒ­ã‚°"""
        self._log(LogLevel.WARNING, message, **kwargs)
    
    def error(self, message: str, error: Optional[Exception] = None, **kwargs):
        """ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°"""
        if error:
            kwargs['error_type'] = error.__class__.__name__
            kwargs['error_message'] = str(error)
        self._log(LogLevel.ERROR, message, **kwargs)
    
    def critical(self, message: str, **kwargs):
        """ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ­ã‚°"""
        self._log(LogLevel.CRITICAL, message, **kwargs)
    
    def debug(self, message: str, **kwargs):
        """ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°"""
        self._log(LogLevel.DEBUG, message, **kwargs)
    
    def _log(self, level: LogLevel, message: str, **kwargs):
        """å†…éƒ¨ãƒ­ã‚°å‡¦ç†"""
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
        if self.metrics:
            if level in [LogLevel.ERROR, LogLevel.CRITICAL]:
                operation = kwargs.get('operation', 'unknown')
                error_type = kwargs.get('error_type', 'unknown')
                self.metrics.record_error(operation, error_type)
            
            # æˆåŠŸãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨˜éŒ²ï¼ˆç‰¹å®šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆï¼‰
            if 'success' in message.lower() or 'completed' in message.lower():
                operation = kwargs.get('operation', 'general')
                duration = kwargs.get('duration', 0.0)
                self.metrics.record_success(operation, duration)
        
        # æ§‹é€ åŒ–ãƒ­ã‚°
        self.structured_logger.info(message, **kwargs)
        
        # æ¨™æº–ãƒ­ã‚°
        log_method = getattr(self.logger, level.value.lower())
        if kwargs:
            message_with_context = f"{message} | Context: {json.dumps(kwargs, default=str)}"
        else:
            message_with_context = message
        log_method(message_with_context)
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆåˆ¤å®š
        self._check_alert_conditions(level, message, kwargs)
    
    def _check_alert_conditions(self, level: LogLevel, message: str, context: dict):
        """ã‚¢ãƒ©ãƒ¼ãƒˆæ¡ä»¶ã®ãƒã‚§ãƒƒã‚¯"""
        # ã‚¨ãƒ©ãƒ¼ç‡ãƒã‚§ãƒƒã‚¯
        if self.metrics and level in [LogLevel.ERROR, LogLevel.CRITICAL]:
            health_summary = self.metrics.get_health_summary()
            success_rate = health_summary.get('success_rate_percent', 100.0)
            
            if success_rate < 50.0:
                self._trigger_alert(AlertLevel.CRITICAL, 
                                  f"Success rate dropped to {success_rate:.1f}%", 
                                  health_summary)
            elif success_rate < 95.0:
                self._trigger_alert(AlertLevel.WARNING, 
                                  f"Success rate at {success_rate:.1f}%", 
                                  health_summary)
        
        # ç·Šæ€¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
        emergency_keywords = ['security breach', 'system down', 'complete failure']
        if any(keyword in message.lower() for keyword in emergency_keywords):
            self._trigger_alert(AlertLevel.EMERGENCY, message, context)
    
    def _trigger_alert(self, alert_level: AlertLevel, message: str, context: dict):
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒˆãƒªã‚¬ãƒ¼"""
        alert_info = {
            'alert_level': alert_level.value,
            'message': message,
            'context': context,
            'timestamp': datetime.now().isoformat(),
            'system': self.name
        }
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šã«åŸºã¥ãé€šçŸ¥ãƒãƒ£ãƒ³ãƒãƒ«
        channels = self.alert_config[alert_level]['channels']
        
        self.critical(f"ğŸš¨ ALERT [{alert_level.value.upper()}]: {message}", 
                     alert_info=alert_info, alert_channels=channels)
        
        # TODO: å®Ÿéš›ã®é€šçŸ¥é€ä¿¡å®Ÿè£…
        # - Slacké€šçŸ¥
        # - Emailé€ä¿¡
        # - SMSé€ä¿¡
        # - é›»è©±é€šçŸ¥ï¼ˆç·Šæ€¥æ™‚ï¼‰
    
    def log_operation_start(self, operation: str, **context) -> dict:
        """æ“ä½œé–‹å§‹ãƒ­ã‚°"""
        start_time = datetime.now()
        operation_context = {
            'operation': operation,
            'start_time': start_time.isoformat(),
            'status': 'started',
            **context
        }
        
        self.info(f"Operation started: {operation}", **operation_context)
        return {'start_time': start_time, 'operation': operation, **context}
    
    def log_operation_end(self, operation_context: dict, success: bool = True, **additional_context):
        """æ“ä½œçµ‚äº†ãƒ­ã‚°"""
        end_time = datetime.now()
        start_time = operation_context.get('start_time')
        operation = operation_context.get('operation')
        
        if start_time:
            duration = (end_time - start_time).total_seconds()
        else:
            duration = 0.0
        
        result_context = {
            **operation_context,
            'end_time': end_time.isoformat(),
            'duration_seconds': duration,
            'status': 'success' if success else 'failed',
            **additional_context
        }
        
        if success:
            self.info(f"Operation completed: {operation} ({duration:.2f}s)", 
                     **result_context)
        else:
            self.error(f"Operation failed: {operation} ({duration:.2f}s)", 
                      **result_context)
    
    def get_health_status(self) -> dict:
        """ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—"""
        if not self.metrics:
            return {"status": "metrics_disabled"}
        
        health_summary = self.metrics.get_health_summary()
        
        # å¥å…¨æ€§åˆ¤å®š
        success_rate = health_summary.get('success_rate_percent', 100.0)
        if success_rate >= 98.0:
            status = "healthy"
        elif success_rate >= 90.0:
            status = "warning"
        elif success_rate >= 70.0:
            status = "degraded"
        else:
            status = "critical"
        
        return {
            "overall_status": status,
            "timestamp": datetime.now().isoformat(),
            **health_summary
        }


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_global_logger: Optional[EnhancedLogger] = None


def get_logger(name: str = "timetree_notifier", 
               log_level: LogLevel = LogLevel.INFO,
               log_file: Optional[Path] = None) -> EnhancedLogger:
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ­ã‚¬ãƒ¼å–å¾—"""
    global _global_logger
    
    if _global_logger is None:
        _global_logger = EnhancedLogger(name, log_level, log_file)
    
    return _global_logger


def setup_logging(config: dict = None):
    """ãƒ­ã‚°è¨­å®šã®åˆæœŸåŒ–"""
    config = config or {}
    
    log_level = LogLevel(config.get('level', 'INFO'))
    log_file_path = config.get('file_path')
    log_file = Path(log_file_path) if log_file_path else None
    
    global _global_logger
    _global_logger = EnhancedLogger(
        name=config.get('name', 'timetree_notifier'),
        log_level=log_level,
        log_file=log_file,
        metrics_enabled=config.get('metrics_enabled', True)
    )
    
    return _global_logger


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨ã®è¨­å®š
    logger = get_logger("test_logger", LogLevel.DEBUG, Path("logs/test.log"))
    
    # æ“ä½œãƒ­ã‚°ã®ãƒ†ã‚¹ãƒˆ
    op_context = logger.log_operation_start("data_sync", source="timetree", target="calendar")
    
    # ä¸€èˆ¬ãƒ­ã‚°
    logger.info("Starting data synchronization", operation="data_sync", records=100)
    logger.warning("Rate limit approaching", current_rate=80, max_rate=100)
    
    # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
    try:
        raise ConnectionError("Network timeout")
    except Exception as e:
        logger.error("Connection failed", error=e, operation="network_request")
    
    # æ“ä½œçµ‚äº†ãƒ­ã‚°
    logger.log_operation_end(op_context, success=True, records_processed=100)
    
    # å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯
    health = logger.get_health_status()
    print("Health Status:", json.dumps(health, indent=2, ensure_ascii=False))